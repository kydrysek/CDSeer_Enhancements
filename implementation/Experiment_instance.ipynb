{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30fa1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1293dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install setuptools wheel -U\n",
    "# !pip install torch -U\n",
    "# !pip install scikit-multiflow\n",
    "# !pip install setuptools\n",
    "# !pip install tqdm\n",
    "# !pip install kneefinder\n",
    "# %pip install numpy_indexed\n",
    "# %pip install river\n",
    "# %pip install python_nameof\n",
    "# %pip install jsonpickle\n",
    "# !pip install capymoa\n",
    "# %pip install shap\n",
    "# %pip install yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc362f",
   "metadata": {},
   "source": [
    "## 1. Imports and low level con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63290d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ola\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2.2.6', '2.3.1', '09/04/25 05:19:28')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy_indexed as npi\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "import river\n",
    "from river.drift.binary import DDM, EDDM\n",
    "from river.drift import ADWIN, PageHinkley\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "from ExperimentControlFlow import *\n",
    "\n",
    "num_cpus = os.cpu_count(); print(f\"Number of CPUs: {num_cpus}\")\n",
    "np.__version__, pd.__version__, time.strftime(\"%D %H:%M:%S\", time.localtime())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca00d9",
   "metadata": {},
   "source": [
    "## 2. Execute experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a620635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WARM_UP_WINDOW_SIZE = 1000    # this actually will have to vary by model tested\n",
    "INSPECTOR_WINDOW_SIZE = 500  # this is treated as a hyperparameter\n",
    "MEMORY_SIZE = 15        # this is treated as a hyperparameter\n",
    "\n",
    "results_of_runs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9230cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_params_list_standard = [(\"DBSCAN_noScale_Model\",(False,False,True,False,False))]\n",
    "\n",
    "# cust_params_list_noSHAP = [(\"NoCluster_noScale\",(False,False,False,False,False)),(\"DBSCAN_Scale_noModel\",(False,False,True,True,False)),\n",
    "#     (\"DBSCAN_noScale_Model\",(False,False,True,False,True)),(\"DBSCAN_Scale_Model\",(False,False,True,True,True))]    \n",
    "# cust_params_list_SHAP_noPoint = [(\"SHAP_noScale_noModel\",(True,False,True,False,False)),(\"SHAP_Scale_noModel\",(True,False,True,True,False)),\n",
    "#     (\"SHAP_noScale_Model\",(True,False,True,False,True)),(\"SHAP_Scale_Model\",(True,False,True,True,True))]\n",
    "# cust_params_list_SHAP_Point = [(\"SHAP_noScale_noModel\",(True,True,True,False,False)),(\"SHAP_Scale_noModel\",(True,True,True,True,False)),\n",
    "#     (\"SHAP_noScale_Model\",(True,True,True,False,True)),(\"SHAP_Scale_Model\",(True,True,True,True,True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc26466",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = \"../datasets/sea/\"\n",
    "\n",
    "path_drift_set = [\n",
    "    ('own_sea_extra_cols.csv',[3000,10000])    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf8047e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thu Sep  4 05:19:29 2025'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e5dd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hokum\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClusteringParams(weight=1, use_SHAP_to_cluster=False, combine_SHAP_with_point=False, perform_clustering=False, scale_for_clustering=False, use_model_pred=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from RunConfig import ClusteringParams\n",
    "\n",
    "a=ClusteringParams(1,False,False,False,False,False)\n",
    "a.blabla()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d2194",
   "metadata": {},
   "source": [
    "# Solely supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a227a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disk space: 603153 MB free\n",
      "Starting on:  ../datasets/sea/own_sea_extra_cols.csv  seed =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 999/4000 [00:00<00:00, 5120.26it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Inspector' object has no attribute 'clustering'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     38\u001b[39m run_config = {\u001b[33m\"\u001b[39m\u001b[33mfile_path\u001b[39m\u001b[33m\"\u001b[39m:full_path,\u001b[33m\"\u001b[39m\u001b[33mtraining_size\u001b[39m\u001b[33m\"\u001b[39m:WARM_UP_WINDOW_SIZE,\u001b[33m\"\u001b[39m\u001b[33mmemory_size\u001b[39m\u001b[33m\"\u001b[39m:MEMORY_SIZE,\u001b[33m\"\u001b[39m\u001b[33minsp_window_size\u001b[39m\u001b[33m\"\u001b[39m:INSPECTOR_WINDOW_SIZE,\n\u001b[32m     39\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcluster_method\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[33m\"\u001b[39m\u001b[33mmodel_object\u001b[39m\u001b[33m\"\u001b[39m:model_object, \u001b[33m\"\u001b[39m\u001b[33mdrift_detector\u001b[39m\u001b[33m\"\u001b[39m:drift_detector, \u001b[33m\"\u001b[39m\u001b[33mkeep_known_labels\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     40\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33minspector_curiosity_factor\u001b[39m\u001b[33m\"\u001b[39m:inspector_curiosity, \u001b[33m\"\u001b[39m\u001b[33moracle_compliance\u001b[39m\u001b[33m\"\u001b[39m:oracle_compliance, \u001b[33m\"\u001b[39m\u001b[33minspector_model\u001b[39m\u001b[33m\"\u001b[39m:RandomForestClassifier(n_estimators=\u001b[32m100\u001b[39m,random_state=\u001b[32m42\u001b[39m),\u001b[38;5;66;03m#KNeighborsClassifier()#\u001b[39;00m\n\u001b[32m     41\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mclustering_params_list\u001b[39m\u001b[33m\"\u001b[39m:clustering_params, \u001b[33m\"\u001b[39m\u001b[33mtrain_forward\u001b[39m\u001b[33m\"\u001b[39m:train_forward, \u001b[33m\"\u001b[39m\u001b[33mrun_quiet\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mdont_propagate\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[32m     43\u001b[39m forw_back_pref = (\u001b[33m\"\u001b[39m\u001b[33mforw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_config[\u001b[33m\"\u001b[39m\u001b[33mtrain_forward\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mback\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m outcomes = \u001b[43mcombined_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mskip_initial\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlimit_size\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mforw_back_pref\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mrepetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrandom_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mrun_count\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m drift_golden_source_capped = [drift \u001b[38;5;28;01mfor\u001b[39;00m drift \u001b[38;5;129;01min\u001b[39;00m drift_golden_source \u001b[38;5;28;01mif\u001b[39;00m drift < LIMIT_DATASET_SIZE]\n\u001b[32m     48\u001b[39m agg_res = score_outcomes(outcomes,drift_golden_source,skip_initial=\u001b[32m0\u001b[39m,train_forward=run_config[\u001b[33m\"\u001b[39m\u001b[33mtrain_forward\u001b[39m\u001b[33m\"\u001b[39m],train_size=WARM_UP_WINDOW_SIZE,mem_size=MEMORY_SIZE)            \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ola\\Documents\\GitHub\\CDSeer_Enhancements\\implementation\\ExperimentControlFlow.py:227\u001b[39m, in \u001b[36mcombined_run\u001b[39m\u001b[34m(run_config, max_size, skip_initial, prefix, repetitions, random_states, save)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcombined_run\u001b[39m(run_config:\u001b[38;5;28mdict\u001b[39m,max_size, skip_initial,prefix:\u001b[38;5;28mstr\u001b[39m,repetitions, random_states,save=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     outcome = [\u001b[43msingle_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mskip_initial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repetitions)]\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outcome\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ola\\Documents\\GitHub\\CDSeer_Enhancements\\implementation\\ExperimentControlFlow.py:211\u001b[39m, in \u001b[36msingle_run\u001b[39m\u001b[34m(run_config, max_size, skip_initial, prefix, random_state, save)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting on: \u001b[39m\u001b[33m\"\u001b[39m,run_config[\u001b[33m\"\u001b[39m\u001b[33mfile_path\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33m seed = \u001b[39m\u001b[33m\"\u001b[39m,random_state)\n\u001b[32m    210\u001b[39m time_start = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m oracle, telemetry = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mskip_initial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m time_end = time.time()\n\u001b[32m    213\u001b[39m saved_file = serialise_run_outcomes(run_config,oracle,telemetry,time_start,time_end,prefix) \u001b[38;5;28;01mif\u001b[39;00m save \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mResults not serialised\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ola\\Documents\\GitHub\\CDSeer_Enhancements\\implementation\\ExperimentControlFlow.py:463\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(file_path, max_size, inspector_curiosity_factor, oracle_compliance, drift_detector, training_size, memory_size, insp_window_size, keep_known_labels, inspector_model, clustering_params_list, train_forward, cluster_method, skip_initial, random_state, run_quiet, run_inspector, dont_propagate, model_class, model_object)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m oracle.number_of_available_points() >= training_size:\n\u001b[32m    462\u001b[39m     initialise_inspector = (inspector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m run_inspector                \n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     model, inspector_tmp = \u001b[43minitialise_model_and_inspector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\u001b[43minspector_curiosity_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmemory_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minsp_window_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m                                                      \u001b[49m\u001b[43mcluster_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43minspector_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minspector_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_known_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_known_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m                                                      \u001b[49m\u001b[43mclustering_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclustering_params_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitialise_inspector\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitialise_inspector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m                                                      \u001b[49m\u001b[43mmodel_object\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m initialise_inspector: inspector = inspector_tmp\n\u001b[32m    469\u001b[39m     telemetry.log_inspector(step_number,inspector)            \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ola\\Documents\\GitHub\\CDSeer_Enhancements\\implementation\\ExperimentControlFlow.py:137\u001b[39m, in \u001b[36minitialise_model_and_inspector\u001b[39m\u001b[34m(model_class, oracle, inspector_curiosity_factor, training_size, memory_size, insp_window_size, cluster_method, random_state, inspector_model, clustering_params, log_me, keep_known_labels, initialise_inspector, model_object)\u001b[39m\n\u001b[32m    131\u001b[39m     \u001b[38;5;66;03m#     \"perform_clustering\":perform_clustering,\"scale_for_clustering\":scale_for_clustering,\"use_model_pred\":use_model_pred}\u001b[39;00m\n\u001b[32m    132\u001b[39m \n\u001b[32m    133\u001b[39m     \n\u001b[32m    134\u001b[39m     \u001b[38;5;66;03m# self.clustering_params = config.get(\"clustering_params\",default_clustering_params)\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# FIXME\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m initialise_inspector:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     inspector = \u001b[43mInspector\u001b[49m\u001b[43m(\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\u001b[43minspector_curiosity_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minsp_window_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minspector_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minspector_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mref_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmain_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mref_model_train_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_known_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_known_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    140\u001b[39m     inspector = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ola\\Documents\\GitHub\\CDSeer_Enhancements\\implementation\\Inspector.py:94\u001b[39m, in \u001b[36mInspector.__init__\u001b[39m\u001b[34m(self, oracle, inspector_curiosity_factor, memory_size, insp_window_size, inspector_model, ref_model, ref_model_train_data, keep_known_labels, config)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.window_labels = deque(iterable=init_labels_maybe,maxlen=\u001b[38;5;28mself\u001b[39m.window_size)\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# C. \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m tmp_window_representation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpoints_representation_full\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# D.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tmp_window_representation[\u001b[32m0\u001b[39m].shape[\u001b[32m0\u001b[39m] > \u001b[38;5;28mself\u001b[39m.feature_threshold:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ola\\Documents\\GitHub\\CDSeer_Enhancements\\implementation\\Inspector.py:25\u001b[39m, in \u001b[36mInspector.points_representation_full\u001b[39m\u001b[34m(self, points)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpoints_representation_full\u001b[39m(\u001b[38;5;28mself\u001b[39m,points):\n\u001b[32m     24\u001b[39m     points = np.array(points)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclustering\u001b[49m.perform_clustering: \u001b[38;5;28;01mreturn\u001b[39;00m points\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mrepr\u001b[39m = points\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.clustering_params.scale_for_clustering: \u001b[38;5;28mrepr\u001b[39m = \u001b[38;5;28mself\u001b[39m.scaler.transform(\u001b[38;5;28mrepr\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Inspector' object has no attribute 'clustering'"
     ]
    }
   ],
   "source": [
    "# Execute ad-hoc experiment \n",
    "DO_AVG=True\n",
    "limit_size=4000\n",
    "oracle_compliance_list=[.0015]\n",
    "inspector_curiosity = .01\n",
    "run_count=1\n",
    "\n",
    "seeds = list(range(1000))\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "if DO_AVG:\n",
    "    # Before running the experiment, check disk space\n",
    "    import shutil\n",
    "    total, used, free = shutil.disk_usage(\".\")\n",
    "    print(f\"Disk space: {free // (2**20)} MB free\")\n",
    "    if free < 100 * 2**20:  # less than 100MB free\n",
    "        raise OSError(\"Not enough disk space to run the experiment. Please free up space and try again.\")\n",
    "    \n",
    "    \n",
    "    res_out1 = []\n",
    "\n",
    "    # model_reference = RandomForestClassifier(random_state=42)\n",
    "    model_object = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    for prefix, conf in cust_params_list_standard:\n",
    "        for train_forward in [True,False]:\n",
    "            for oracle_compliance in oracle_compliance_list:\n",
    "                for path, drift_golden_source in path_drift_set:                \n",
    "                    full_path = path_dir+path\n",
    "                    drift_detector = river.drift.PageHinkley()\n",
    "                    # clustering_params={\"weight\":1,\"use_SHAP_to_cluster\":conf[0],\"combine_SHAP_with_point\":conf[1],\n",
    "                    #                         \"perform_clustering\":conf[2],\"scale_for_clustering\":conf[3],\"use_model_pred\":conf[4]}\n",
    "                    clustering_params = ClusteringParams(weight=1,use_SHAP_to_cluster=conf[0],combine_SHAP_with_point=conf[1],\n",
    "                                            perform_clustering=conf[2],scale_for_clustering=conf[3],use_model_pred=conf[4])\n",
    "                    \n",
    "                \n",
    "                    run_config = {\"file_path\":full_path,\"training_size\":WARM_UP_WINDOW_SIZE,\"memory_size\":MEMORY_SIZE,\"insp_window_size\":INSPECTOR_WINDOW_SIZE,\n",
    "                                \"cluster_method\":None,\"model_object\":model_object, \"drift_detector\":drift_detector, \"keep_known_labels\":False,\n",
    "                                \"inspector_curiosity_factor\":inspector_curiosity, \"oracle_compliance\":oracle_compliance, \"inspector_model\":RandomForestClassifier(n_estimators=100,random_state=42),#KNeighborsClassifier()#\n",
    "                                \"clustering_params_list\":clustering_params, \"train_forward\":train_forward, \"run_quiet\":False, \"dont_propagate\":False}\n",
    "                    \n",
    "                    forw_back_pref = (\"forw\" if run_config[\"train_forward\"] else \"back\")\n",
    "\n",
    "                    outcomes = combined_run(run_config,max_size=limit_size,skip_initial=0,prefix=f\"{limit_size}_{forw_back_pref}_{prefix}\",repetitions=run_count,random_states=seeds[:run_count],save=True)\n",
    "\n",
    "                    drift_golden_source_capped = [drift for drift in drift_golden_source if drift < LIMIT_DATASET_SIZE]\n",
    "                    agg_res = score_outcomes(outcomes,drift_golden_source,skip_initial=0,train_forward=run_config[\"train_forward\"],train_size=WARM_UP_WINDOW_SIZE,mem_size=MEMORY_SIZE)            \n",
    "                    agg_res[\"files\"] = [outcome[0] for outcome in outcomes]\n",
    "                    print(f\"\\ncumultive results: {agg_res}\")\n",
    "                    \n",
    "                    saved_file = serialise_aggregate_results(run_config,agg_res,f\"{forw_back_pref}_{prefix}\")\n",
    "                    print(f\"aggregate_file={saved_file}\\n\\n\")\n",
    "                    res_out1 += [saved_file]\n",
    "            \n",
    "            \n",
    "    print(f\"Results gathered\\n{res_out1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bfefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_results_to_df(res_out1,save_as_name=\"SHAP_4.csv\", rescore_drift=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7d2663",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
